{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import requests\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPClassifier:\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "    def __init__(self, imgURL: str, labels: list[str]):\n",
    "        img = Image.open(requests.get(imgURL, stream=True).raw)\n",
    "        self.labels = labels\n",
    "        self.inputs = CLIPClassifier.processor(text=labels, images=img, return_tensors=\"pt\", padding=True)\n",
    "    \n",
    "    def fit(self):\n",
    "        return CLIPClassifier.model(**self.inputs)\n",
    "\n",
    "    def predict(self, printInfo=True):\n",
    "        outputs = self.fit()\n",
    "        logits_per_image = outputs.logits_per_image\n",
    "        probs = logits_per_image.softmax(dim=1)\n",
    "        pred = self.labels[probs.argmax().item()]\n",
    "        if printInfo:\n",
    "            print(\"=====================\")\n",
    "            print(''.join([f\"label: {self.labels[i]}, prob: {probs[0, i]}\\n\" for i in range(len(self.labels))]))\n",
    "            print(f\"Prediction: {pred}\")\n",
    "            print(\"=====================\")\n",
    "        return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Photo Of A Cat\n",
    "\n",
    "<img src=\"http://images.cocodataset.org/val2017/000000039769.jpg\" alt=\"image\" width=\"200px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "label: cat, prob: 0.9932803511619568\n",
      "label: dog, prob: 0.006719659082591534\n",
      "\n",
      "Prediction: cat\n",
      "=====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = CLIPClassifier(\"http://images.cocodataset.org/val2017/000000039769.jpg\", [\"cat\", \"dog\"])\n",
    "cat.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Photo Of A Dog\n",
    "\n",
    "<img src=\"https://images.unsplash.com/photo-1587402092301-725e37c70fd8?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxzZWFyY2h8MXx8cHVwcHklMjBkb2d8ZW58MHx8MHx8&w=1000&q=80\" alt=\"image\" width=\"200px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "label: cat, prob: 0.003522968152537942\n",
      "label: dog, prob: 0.9964770674705505\n",
      "\n",
      "Prediction: dog\n",
      "=====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog = CLIPClassifier(\"https://images.unsplash.com/photo-1587402092301-725e37c70fd8?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxzZWFyY2h8MXx8cHVwcHklMjBkb2d8ZW58MHx8MHx8&w=1000&q=80\", [\"cat\", \"dog\"])\n",
    "dog.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Photo Of A Snake\n",
    "\n",
    "<img src=\"https://images.foxtv.com/static.foxla.com/www.foxla.com/content/uploads/2021/12/764/432/snake.jpg?ve=1&tl=1\" alt=\"image\" width=\"200px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "label: snake, prob: 0.9983910918235779\n",
      "label: hose, prob: 0.001608935184776783\n",
      "\n",
      "Prediction: snake\n",
      "=====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'snake'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake = CLIPClassifier(\"https://images.foxtv.com/static.foxla.com/www.foxla.com/content/uploads/2021/12/764/432/snake.jpg?ve=1&tl=1\", [\"snake\", \"hose\"])\n",
    "snake.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Photo Of Oranges\n",
    "\n",
    "<img src=\"http://images.cocodataset.org/val2017/000000050896.jpg\" alt=\"image\" width=\"200px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "label: orange, prob: 0.7922490835189819\n",
      "label: tangerine, prob: 0.1991378664970398\n",
      "label: lemon, prob: 0.008613087236881256\n",
      "\n",
      "Prediction: orange\n",
      "=====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'orange'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oranges = CLIPClassifier(\"http://images.cocodataset.org/val2017/000000050896.jpg\", [\"orange\", \"tangerine\", \"lemon\"])\n",
    "oranges.predict()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "975c7e576800f19e1e9e93b311ea6fb1ed84c8a9c8a6145f3657bcaa958c65e9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('AI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
